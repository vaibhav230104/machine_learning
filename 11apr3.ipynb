{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29316484-624c-4491-b667-c4434f95cfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. What is Random Forest Regressor?\n",
    "\n",
    "# Random Forest Regressor is an ensemble learning method based on decision trees used for regression tasks. It constructs multiple decision trees during training and outputs the mean prediction of the individual trees as the final prediction.\n",
    "\n",
    "# Q2. How does Random Forest Regressor reduce the risk of overfitting?\n",
    "\n",
    "# Random Forest Regressor reduces overfitting by:\n",
    "# - Utilizing multiple trees trained on different subsets of the data (bagging), which helps in reducing variance.\n",
    "# - Adding randomness by using a subset of features at each split, making each tree less sensitive to specific features or noise in the data.\n",
    "\n",
    "# Q3. How does Random Forest Regressor aggregate the predictions of multiple decision trees?\n",
    "\n",
    "# Random Forest Regressor aggregates predictions by taking the mean (or median) of the outputs from individual decision trees for regression tasks.\n",
    "\n",
    "# Q4. What are the hyperparameters of Random Forest Regressor?\n",
    "\n",
    "# Hyperparameters include:\n",
    "# - n_estimators: Number of trees in the forest.\n",
    "# - max_depth: Maximum depth allowed for each tree.\n",
    "# - min_samples_split: Minimum number of samples required to split a node.\n",
    "# - max_features: Number of features to consider for the best split.\n",
    "# - criterion: Function to measure the quality of a split.\n",
    "# ... and others.\n",
    "\n",
    "# Q5. What is the difference between Random Forest Regressor and Decision Tree Regressor?\n",
    "\n",
    "# Random Forest Regressor:\n",
    "# - Uses multiple decision trees.\n",
    "# - Reduces overfitting by bagging and feature randomness.\n",
    "# - Aggregates predictions of multiple trees.\n",
    "\n",
    "# Decision Tree Regressor:\n",
    "# - Uses a single decision tree.\n",
    "# - Prone to overfitting without constraints.\n",
    "# - Generates predictions based on a single tree.\n",
    "\n",
    "# Q6. What are the advantages and disadvantages of Random Forest Regressor?\n",
    "\n",
    "# Advantages:\n",
    "# - Reduced overfitting compared to single decision trees.\n",
    "# - Handles missing values and maintains accuracy with large datasets.\n",
    "# - Effective for capturing complex relationships in data.\n",
    "\n",
    "# Disadvantages:\n",
    "# - Can be computationally expensive with a large number of trees.\n",
    "# - Might be more challenging to interpret compared to a single decision tree.\n",
    "\n",
    "# Q7. What is the output of Random Forest Regressor?\n",
    "\n",
    "# The output of the Random Forest Regressor is the predicted continuous value, which is typically the mean (or median) prediction of all the individual trees in the forest.\n",
    "\n",
    "# Q8. Can Random Forest Regressor be used for classification tasks?\n",
    "\n",
    "# Yes, Random Forest can be used for classification tasks as well, where it's called Random Forest Classifier. It operates similarly but predicts discrete classes instead of continuous values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f503134-45ef-44b0-9057-9023727e4b00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
