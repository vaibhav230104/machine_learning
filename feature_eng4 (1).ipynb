{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3168466d-f59c-49f4-91d4-5ee745e108e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1 Data encoding refers to the process of converting categorical or non-numerical data into a numerical format that can be processed by machine learning algorithms.\n",
    "# Uses:\n",
    "# Feature Engineering.\n",
    "# Increased model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4cb00a3-d389-46b5-8b57-40dac4ba0d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2 Nominal encoding, also known as label encoding or integer encoding, is a technique that assigns a unique numerical value to each category in a categorical variable.\n",
    "# Suppose we have a dataset containing information about different car models, including their brand. The brand column has categorical values such as \"Toyota,\" \"Ford,\" \"Honda,\" and \"Chevrolet.\" We can use nominal encoding to convert these categories into numerical values:\n",
    "\n",
    "# Brand:                         \n",
    "# Toyota\n",
    "# Ford\n",
    "# Honda\n",
    "# Chevrolet\n",
    "\n",
    "# After nominal encoding, the brand column would be transformed as follows:\n",
    "\n",
    "# Brand:\n",
    "# 1\n",
    "# 2\n",
    "# 3\n",
    "# 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2e7a0b3-74f8-48a5-8232-0aa071024cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3 Nominal encoding is preferred over one-hot encoding in situations where there is no inherent order or hierarchy among the categories, and the number of categories is relatively large. Here's a practical example:\n",
    "\n",
    "# Suppose we have a dataset containing information about different countries, including their continents. The continent column has categorical values such as \"Asia,\" \"Europe,\" \"North America,\" and \"South America.\" If we were to use one-hot encoding, each category would be represented by a binary feature column (e.g., Asia: [1, 0, 0, 0], Europe: [0, 1, 0, 0], etc.). However, in this case, there is no inherent order or hierarchy among the continents, and the number of continents is relatively large.\n",
    "\n",
    "# Using nominal encoding in this scenario would assign a unique numerical value to each continent (e.g., Asia: 1, Europe: 2, North America: 3, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "715409a6-ca27-4eb5-a92e-adefac872acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q4 If the dataset contains categorical data with 5 unique values, I would choose to use one-hot encoding to transform the data into a format suitable for machine learning algorithms.\n",
    "\n",
    "# One-hot encoding is suitable in this scenario because it creates binary features for each unique category. Since there are only 5 unique values, the resulting one-hot encoded dataset would have 5 binary features. Each feature represents a specific category and takes the value of 1 if the instance belongs to that category and 0 otherwise.\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "lst = [['A'],['B'],['C'],['D'],['E']]\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit_transform(lst).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9c5c24a-9198-45ef-91a4-a97561c3943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5 for total no of new_column = no of unique Category in first column + no of unique Category in second column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9ad6837-438f-4f0c-8a19-6b68e379c84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6 We should use one-hot encoding in this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "988d48c4-97ae-4836-8463-679dde595f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7 We either use one-hot encoding or trarget-guided encoding.\n",
    "#for using this first import library sklearn.preprocessing from this we can import our suitable lib."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
