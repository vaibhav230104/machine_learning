{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "059b292f-67af-45cc-b83b-747da68288bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. How does bagging reduce overfitting in decision trees?\n",
    "\n",
    "# Bagging reduces overfitting in decision trees by training multiple trees on different subsets of the data with replacement. As these trees are combined by averaging their predictions, the ensemble model becomes less sensitive to noise or outliers present in any single tree.\n",
    "\n",
    "# Q2. What are the advantages and disadvantages of using different types of base learners in bagging?\n",
    "\n",
    "# Advantages:\n",
    "# - Diversity in base learners can enhance the overall predictive performance.\n",
    "# - Different learners can capture different aspects of the data, leading to a more robust model.\n",
    "\n",
    "# Disadvantages:\n",
    "# - If the base learners are similar, diversity won't be achieved, limiting the effectiveness of bagging.\n",
    "# - Using complex models as base learners might increase computational complexity and training time.\n",
    "\n",
    "# Q3. How does the choice of base learner affect the bias-variance tradeoff in bagging?\n",
    "\n",
    "# A complex base learner might have low bias but high variance. Bagging with such a base learner can reduce variance by averaging, improving the overall model's performance. It often helps to strike a balance between bias and variance.\n",
    "\n",
    "# Q4. Can bagging be used for both classification and regression tasks? How does it differ in each case?\n",
    "\n",
    "# Yes, bagging can be used for both classification and regression tasks. In classification, bagging combines predictions through majority voting, while in regression, it averages the predictions.\n",
    "\n",
    "# Q5. What is the role of ensemble size in bagging? How many models should be included in the ensemble?\n",
    "\n",
    "# The ensemble size in bagging can impact the model's performance. Initially, increasing the ensemble size tends to improve performance, but after a certain point, the benefits may diminish. Typically, larger ensembles tend to perform better, but there's a trade-off with computational cost.\n",
    "\n",
    "# Q6. Can you provide an example of a real-world application of bagging in machine learning?\n",
    "\n",
    "# Bagging is widely used in various real-world applications:\n",
    "# - In finance, for stock market prediction using multiple models trained on different historical data subsets.\n",
    "# - In healthcare, for disease diagnosis by aggregating predictions from various medical tests or data sources.\n",
    "# - In e-commerce, for fraud detection by combining predictions from multiple anomaly detection models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d663c3-c955-4cbb-91ba-6434a595c77b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
